{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6-2: You Only Look Once â€“ \"Understanding Object Detection\"\n",
    "\n",
    "**Course:** CSEN 342: Deep Learning  \n",
    "**Topic:** Object Detection, YOLO, Intersection over Union (IoU), and Non-Max Suppression (NMS)\n",
    "\n",
    "## Objective\n",
    "Object Detection models like YOLO (You Only Look Once) don't just output a class label; they output a **dense grid of bounding boxes**. A single forward pass might produce thousands of candidate boxes, most of which are overlapping or low-confidence.\n",
    "\n",
    "In this tutorial, we will peel back the layers of the detection pipeline. We won't train a model (which takes days); instead, we will implement the **post-processing logic** that turns raw network output into clean detections.\n",
    "\n",
    "We will:\n",
    "1.  **Decode the Tensor:** Understand the famous $7\\times7\\times30$ YOLO output tensor.\n",
    "2.  **Calculate IoU:** Implement Intersection over Union to measure how much two boxes overlap.\n",
    "3.  **Implement NMS:** Write the Non-Max Suppression algorithm from scratch to remove duplicate detections.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The YOLO Output Tensor\n",
    "\n",
    "As described in the lecture (Slide 94), the original YOLO model divides the image into a $7\\times7$ grid. Each cell predicts:\n",
    "1.  **2 Bounding Boxes** ($x, y, w, h, \\text{confidence}$ for each).\n",
    "2.  **20 Class Probabilities** (for PASCAL VOC).\n",
    "\n",
    "Total depth = $2 \\times 5 + 20 = 30$.  \n",
    "Final Tensor Shape: $(7, 7, 30)$.\n",
    "\n",
    "Let's write a function to decode a prediction vector from one of these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Define the class names for PASCAL VOC (20 classes)\n",
    "VOC_CLASSES = [\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \n",
    "    \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "]\n",
    "\n",
    "def decode_yolo_cell(cell_tensor, grid_x, grid_y, img_width=448, img_height=448):\n",
    "    \"\"\"\n",
    "    Converts raw YOLO output for a single cell into absolute bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        cell_tensor: tensor of shape (30,) -> [x1, y1, w1, h1, c1, x2, y2, w2, h2, c2, class_probs(20)]\n",
    "        grid_x, grid_y: coordinates of the grid cell (0-6)\n",
    "    \"\"\"\n",
    "    # Split the tensor\n",
    "    # First 5: Box 1 (x, y, w, h, conf)\n",
    "    # Next 5: Box 2 (x, y, w, h, conf)\n",
    "    # Last 20: Class probabilities\n",
    "    box1_data = cell_tensor[0:5]\n",
    "    box2_data = cell_tensor[5:10]\n",
    "    class_probs = cell_tensor[10:]\n",
    "    \n",
    "    # Find best class\n",
    "    class_score, class_idx = torch.max(class_probs, 0)\n",
    "    class_name = VOC_CLASSES[class_idx]\n",
    "    \n",
    "    decoded_boxes = []\n",
    "    \n",
    "    # Process both boxes\n",
    "    for data in [box1_data, box2_data]:\n",
    "        x, y, w, h, conf = data\n",
    "        \n",
    "        # YOLO mechanics (simplified):\n",
    "        # x, y are offsets relative to the grid cell bounds (0 to 1)\n",
    "        # w, h are normalized relative to image size\n",
    "        \n",
    "        # Convert to absolute pixel coords\n",
    "        cell_width = img_width / 7\n",
    "        cell_height = img_height / 7\n",
    "        \n",
    "        center_x = (grid_x + x) * cell_width\n",
    "        center_y = (grid_y + y) * cell_height\n",
    "        abs_w = w * img_width\n",
    "        abs_h = h * img_height\n",
    "        \n",
    "        # Convert Center-Width-Height to Top-Left-Bottom-Right (x1, y1, x2, y2)\n",
    "        x1 = center_x - abs_w / 2\n",
    "        y1 = center_y - abs_h / 2\n",
    "        x2 = center_x + abs_w / 2\n",
    "        y2 = center_y + abs_h / 2\n",
    "        \n",
    "        # Final Score = Box Confidence * Class Probability\n",
    "        final_score = conf * class_score\n",
    "        \n",
    "        decoded_boxes.append([x1.item(), y1.item(), x2.item(), y2.item(), final_score.item(), class_name])\n",
    "        \n",
    "    return decoded_boxes\n",
    "\n",
    "print(\"Decoder function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Intersection over Union (IoU)\n",
    "\n",
    "To remove duplicates, we need to know if two boxes overlap significantly. **IoU** is the standard metric.\n",
    "\n",
    "$$ \\text{IoU} = \\frac{\\text{Area of Intersection}}{\\text{Area of Union}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # boxA = [x1, y1, x2, y2]\n",
    "    # 1. Determine the coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # 2. Compute the area of intersection rectangle\n",
    "    interWidth = max(0, xB - xA)\n",
    "    interHeight = max(0, yB - yA)\n",
    "    interArea = interWidth * interHeight\n",
    "\n",
    "    # 3. Compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    # 4. Compute the intersection over union\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "    return iou\n",
    "\n",
    "# Test it\n",
    "box1 = [50, 50, 150, 150] # 100x100 box\n",
    "box2 = [60, 60, 160, 160] # Shifted by 10\n",
    "box3 = [200, 200, 300, 300] # Non-overlapping\n",
    "\n",
    "print(f\"IoU (Overlap): {calculate_iou(box1, box2):.2f}\")\n",
    "print(f\"IoU (No Overlap): {calculate_iou(box1, box3):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Non-Max Suppression (NMS)\n",
    "\n",
    "Detectors often output multiple boxes for the same object (e.g., one slightly to the left, one slightly to the right). **NMS** cleans this up.\n",
    "\n",
    "**The Algorithm:**\n",
    "1.  Discard all boxes with low confidence score.\n",
    "2.  Sort remaining boxes by confidence (descending).\n",
    "3.  Pick the highest confidence box $B$ as a valid detection.\n",
    "4.  Discard any other box that has high IoU with $B$ (duplicate).\n",
    "5.  Repeat until no boxes remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, iou_threshold=0.5, score_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        boxes: List of [x1, y1, x2, y2, score, class_name]\n",
    "    Returns:\n",
    "        List of kept boxes\n",
    "    \"\"\"\n",
    "    # 1. Filter by score threshold\n",
    "    boxes = [b for b in boxes if b[4] > score_threshold]\n",
    "    \n",
    "    # 2. Sort by confidence (highest first)\n",
    "    boxes = sorted(boxes, key=lambda x: x[4], reverse=True)\n",
    "    \n",
    "    kept_boxes = []\n",
    "    \n",
    "    while len(boxes) > 0:\n",
    "        # Pick the best box\n",
    "        current_box = boxes.pop(0)\n",
    "        kept_boxes.append(current_box)\n",
    "        \n",
    "        # Compare with rest\n",
    "        remaining_boxes = []\n",
    "        for other_box in boxes:\n",
    "            iou = calculate_iou(current_box[:4], other_box[:4])\n",
    "            \n",
    "            # If they are different objects (low IoU) OR different classes, keep it\n",
    "            if iou < iou_threshold or current_box[5] != other_box[5]:\n",
    "                remaining_boxes.append(other_box)\n",
    "        \n",
    "        boxes = remaining_boxes\n",
    "        \n",
    "    return kept_boxes\n",
    "\n",
    "print(\"NMS Defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Putting it Together (Simulation)\n",
    "\n",
    "We will generate a noisy set of predictions (simulating a YOLO raw output) and see if NMS can clean it up.\n",
    "\n",
    "**Scenario:** A \"Dog\" in the center, and a \"Person\" to the right. The model outputs many overlapping boxes for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic \"Raw\" Detections\n",
    "# Format: [x1, y1, x2, y2, score, class]\n",
    "raw_detections = []\n",
    "\n",
    "# Cluster 1: The Dog (Good box + 2 duplicates)\n",
    "raw_detections.append([100, 100, 200, 300, 0.9, \"dog\"])       # Perfect\n",
    "raw_detections.append([105, 102, 198, 298, 0.75, \"dog\"])      # Slightly off\n",
    "raw_detections.append([90, 90, 210, 310, 0.6, \"dog\"])         # Too big\n",
    "\n",
    "# Cluster 2: The Person (Good box + 1 duplicate)\n",
    "raw_detections.append([300, 150, 400, 400, 0.85, \"person\"])   # Perfect\n",
    "raw_detections.append([310, 160, 410, 410, 0.82, \"person\"])   # Shifted\n",
    "\n",
    "# Cluster 3: Noise (Low confidence background)\n",
    "raw_detections.append([50, 50, 80, 80, 0.1, \"bird\"])          # Noise\n",
    "\n",
    "# Run NMS\n",
    "cleaned_detections = non_max_suppression(raw_detections, iou_threshold=0.5, score_threshold=0.5)\n",
    "\n",
    "# Visualization Helper\n",
    "def draw_boxes(ax, boxes, title):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(0, 500); ax.set_ylim(500, 0)\n",
    "    # Draw pseudo-image\n",
    "    ax.add_patch(patches.Rectangle((0,0), 500, 500, color='#f0f0f0'))\n",
    "    \n",
    "    for b in boxes:\n",
    "        x1, y1, x2, y2, score, label = b\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        \n",
    "        # Color by class\n",
    "        color = 'blue' if label == 'dog' else 'red' if label == 'person' else 'green'\n",
    "        \n",
    "        rect = patches.Rectangle((x1, y1), w, h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1-5, f\"{label} {score:.2f}\", color=color, fontsize=10, weight='bold')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "draw_boxes(axs[0], raw_detections, f\"Raw Output ({len(raw_detections)} boxes)\")\n",
    "draw_boxes(axs[1], cleaned_detections, f\"After NMS ({len(cleaned_detections)} boxes)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "You can clearly see how NMS cleaned up the output. It kept the highest confidence \"Dog\" box (0.9) and suppressed the overlapping duplicates (0.75, 0.6), and removed the low-confidence \"Bird\" noise entirely.\n",
    "\n",
    "This logic runs thousands of times per second in self-driving cars and security cameras!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
