{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2-3: Advanced Regularization â€“ \"Mixup & Cutout\"\n",
    "\n",
    "**Course:** CSEN 342: Deep Learning  \n",
    "**Topic:** State-of-the-art Regularization, Custom Transforms, and Robustness\n",
    "\n",
    "## Objective\n",
    "Standard regularization (L2, Dropout) is often not enough for modern deep learning tasks. In this tutorial, we will implement two advanced data augmentation techniques discussed in class:\n",
    "\n",
    "1.  **Cutout:** Randomly masking out square regions of the input image. This forces the model to look at the \"whole\" object rather than relying on a single distinctive feature (like a cat's ear).\n",
    "2.  **Mixup:** Training on linear combinations of pairs of images and their labels. This encourages the model to behave linearly in-between training examples.\n",
    "\n",
    "We will implementation these from scratch and test if they make our model more **robust** to noise.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Cutout\n",
    "\n",
    "Cutout is a form of data augmentation where random square regions of the input image are zeroed out. We will implement this as a custom class compatible with `torchvision.transforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Import utility functions\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from utils import download_fashion_mnist\n",
    "\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            # Choose center of the hole\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "\n",
    "# --- Visualizing Cutout ---\n",
    "# Standard transform\n",
    "base_transform = transforms.Compose([transforms.ToTensor()])\n",
    "# Cutout transform\n",
    "cutout_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Cutout(n_holes=1, length=16) # Cut out a 16x16 box (large!)\n",
    "])\n",
    "# Load Fashion-MNIST dataset\n",
    "download_fashion_mnist()\n",
    "dataset = torchvision.datasets.FashionMNIST(root='../data', train=True, download=False, transform=base_transform)\n",
    "img, label = dataset[0]\n",
    "\n",
    "# Apply Cutout manually to visualize\n",
    "img_cutout = cutout_transform(torchvision.transforms.ToPILImage()(img))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1); plt.imshow(img.squeeze(), cmap='gray'); plt.title(\"Original\")\n",
    "plt.subplot(1,2,2); plt.imshow(img_cutout.squeeze(), cmap='gray'); plt.title(\"With Cutout\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing Mixup\n",
    "\n",
    "Mixup is unique because it changes not just the input $x$, but also the target label $y$. \n",
    "\n",
    "Instead of training on $(x_i, y_i)$, we train on:\n",
    "$$ \\tilde{x} = \\lambda x_i + (1-\\lambda) x_j $$\n",
    "$$ \\tilde{y} = \\lambda y_i + (1-\\lambda) y_j $$\n",
    "\n",
    "Where $\\lambda$ is drawn from a Beta distribution. This forces the network to output \"40% T-shirt, 60% Shoe\" rather than just \"Shoe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixup Helper Functions\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    '''Loss function for mixup: linear combination of losses'''\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# Visualization of Mixup\n",
    "# Let's grab a batch and mix two images\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "data_iter = iter(loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "mixed_images, y_a, y_b, lam = mixup_data(images, labels, alpha=1.0, use_cuda=False)\n",
    "\n",
    "print(f\"Mixing Lambda: {lam:.2f}\")\n",
    "print(f\"Label A: {y_a[0]}, Label B: {y_b[0]}\")\n",
    "\n",
    "plt.imshow(mixed_images[0].squeeze(), cmap='gray')\n",
    "plt.title(f\"Mixup Image (Label: {lam:.2f}*A + {1-lam:.2f}*B)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Robustness Training Loop\n",
    "\n",
    "We will now train two models:\n",
    "1.  **Baseline:** Standard training.\n",
    "2.  **Mixup:** Training using the mixup functions we defined.\n",
    "\n",
    "We will then test both models on a **Noisy Test Set** (images with added Gaussian noise) to see which model holds up better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Simple CNN for speed\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "# Setup DataLoaders\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.FashionMNIST(root='../data', train=False, download=False, transform=base_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "def train_mixup(model, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # --- Mixup Logic ---\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=1.0, use_cuda=torch.cuda.is_available())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # --- Mixup Loss ---\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1} Complete\")\n",
    "    return model\n",
    "\n",
    "def train_baseline(model, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Complete\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Baseline Model...\")\n",
    "model_base = SimpleCNN()\n",
    "train_baseline(model_base, epochs=5)\n",
    "\n",
    "print(\"\\nTraining Mixup Model...\")\n",
    "model_mix = SimpleCNN()\n",
    "train_mixup(model_mix, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Robustness Test (Adding Noise)\n",
    "\n",
    "Now we evaluate both models on the test set, but we add random Gaussian noise to the test images. A robust model should degrade gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(model, noise_level=0.0):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            # Add noise\n",
    "            inputs = inputs + noise_level * torch.randn_like(inputs)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "print(\"--- Robustness Evaluation ---\")\n",
    "noise_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "acc_base = []\n",
    "acc_mix = []\n",
    "\n",
    "for noise in noise_levels:\n",
    "    a_b = evaluate_robustness(model_base, noise)\n",
    "    a_m = evaluate_robustness(model_mix, noise)\n",
    "    acc_base.append(a_b)\n",
    "    acc_mix.append(a_m)\n",
    "    print(f\"Noise {noise}: Baseline={a_b:.2f}%, Mixup={a_m:.2f}%\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(noise_levels, acc_base, '-o', label='Baseline')\n",
    "plt.plot(noise_levels, acc_mix, '-o', label='Mixup')\n",
    "plt.title(\"Robustness to Gaussian Noise\")\n",
    "plt.xlabel(\"Noise Level (std dev)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "You should observe that while the **Baseline** model drops in accuracy quickly as noise increases, the **Mixup** model maintains its accuracy longer. This is because Mixup forces the model to learn smoother decision boundaries that are less sensitive to small perturbations in the input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "342wi26",
   "language": "python",
   "name": "342wi26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
